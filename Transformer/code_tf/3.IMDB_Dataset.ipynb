{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ebd0c51",
   "metadata": {},
   "source": [
    "## Download and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n",
    "                                  untar=True, cache_dir='.',\n",
    "                                  cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0ab10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f54bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c68e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f6b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f55c2db",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e65740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f65d5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "seed = 12345\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "                            '../aclImdb/train', batch_size=batch_size, \n",
    "                            validation_split=0.2,\n",
    "                            subset='training', seed=seed)\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "                            '../aclImdb/train', batch_size=batch_size, \n",
    "                            validation_split=0.2,\n",
    "                            subset='validation', seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2846310e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1849e8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "How to lose friends and alienate people is decent comedy with a bit of romantic approach.<br /><br />It's actually a story of Sidney Young(Simon Pegg) breaking through in journalist and magazine writing business which is interpreted in a funny way. Simon Pegg made an OK appearance, slightly worse than his usual. Movie is not hilarious or funny all the way or anything like that but it has its moments, and those moments are really hilarious.<br /><br />I recommend this fun and worth watching American with English cream comedy to all people who just wanna sit, relax and enjoy movie for what it is. If you're about to watch this movie with critical approach then you should pass unless you want to be disappointed and start trashing it.\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds:\n",
    "    print(label_batch[0].numpy())\n",
    "    print(text_batch[0].numpy().decode())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33202057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d109c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ffe579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to lose friends and alienate people is decent comedy with a bit of romantic approach  its actually a story of sidney youngsimon pegg breaking through in journalist and magazine writing business which is interpreted in a funny way simon pegg made an ok appearance slightly worse than his usual movie is not hilarious or funny all the way or anything like that but it has its moments and those moments are really hilarious  i recommend this fun and worth watching american with english cream comedy to all people who just wanna sit relax and enjoy movie for what it is if youre about to watch this movie with critical approach then you should pass unless you want to be disappointed and start trashing it\n"
     ]
    }
   ],
   "source": [
    "output = custom_standardization(text_batch[0].numpy().decode())\n",
    "print(output.numpy().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa8a85a",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83546eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocal_size   = 20000\n",
    "sequence_len = 200\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
    "    )\n",
    "\n",
    "vectorization = tf.keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocal_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_len,\n",
    ")\n",
    "\n",
    "vectorization.adapt(train_ds.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d6686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e862776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorization(text), label\n",
    "\n",
    "train_ds = train_ds.map(vectorize_text)\n",
    "val_ds = val_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccf871ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[  280    43   457  1037   107    31     2   201    58    31     2   201\n",
      "   268     9    13    37   270    15    11   647    12    10    67  4890\n",
      "    42     2     1     5     2   134     3   199     9  1823   368    46\n",
      "   113    18     9     7    21     9     7    30   146     2    62     7\n",
      "   160   156    15     2    80     5     2  4434  2751   326  3058     9\n",
      "     1   708    20     2  8875     5     2    80    32  4899  1714     2\n",
      " 18710     2  4535     1     5     2    80    32  4149  1829  1072    20\n",
      "     2  1837   505     6     2   212    12     2  1242  1588  6270    41\n",
      "    54     2     1     1    32     2   166  1059  4751    36  1207    99\n",
      "   519     6 11394     2  4822    82   574     3  1597 16682    65 18015\n",
      "     4  7910  1902     8     2    19  4679    11    77    12    34   456\n",
      "     6    66     2  1873  6245    20     2  1837    30     5   128  6705\n",
      "    25    75   249     8     1  2837   862     8     2   751  3175   450\n",
      "    29   484    36    43  2377   447 18015     3  4183   989  2419    90\n",
      "    32     2  7702  1242    25    75  3981  3900   138     4     1     1\n",
      "  1714 11046     2     1     1     5     2  1242     8    61     4    52\n",
      "   662 19995     7  9678    32    33  1242  1484]\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds:\n",
    "    print(label_batch[0].numpy())\n",
    "    print(text_batch.numpy()[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c58c8da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[    4  2413  1262    17    12    43     4     1   496  4734 11601     7\n",
      "    14   202   873  6500     1    43   349   104    85   341    18    47\n",
      "     7    40   139    42    11    28    74  6861   122  1782    87     5\n",
      "    30   822   182     6    66    11   469     1   162     1     1    10\n",
      "    13    37  7521    32    39  1297    10    67     6   810     2    17\n",
      "    37    10    97   103    39   170     3   170    53     7     4  4328\n",
      "     5  2981  3638  4224    32     2   320   970   683   142    21     2\n",
      "    60    28    36    13 13690    32    11   180   509     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in val_ds:\n",
    "    print(label_batch[0].numpy())\n",
    "    print(text_batch.numpy()[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff20dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a29080",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062b100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42a4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
